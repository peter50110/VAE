# -*- coding: utf-8 -*-
"""Audio VAE for IR generation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C1aw8tmoMo221S5HtLZszsqE9NhryikW

# Prepared Audio Dataset

## Test reader
"""

import gdown
url="https://drive.google.com/drive/folders/1E_bGQZKu6gcAc1lDcZctSZZuj8xt2LtW?usp=sharing"
gdown.download_folder(url, quiet=True, use_cookies=False)

from os.path import dirname, join as pjoin
from scipy.io import wavfile
import scipy.io

# Get the filename for an example .wav file from the tests/data directory.
data_dir = pjoin('/content/Wav_IR_dataset/Marshall1960A_1105', 'SEVR2')
wav_fname = pjoin(data_dir, 'Marshall_SEVR 2.wav')

print(wav_fname)

from os.path import dirname, join as pjoin
from scipy.io import wavfile
import scipy.io
import numpy as np


# Load the .wav file contents.
samplerate, data = wavfile.read(wav_fname)
print(f"number of channels = {data.shape[0]}")
length = data.shape[0] / samplerate
print(f"length = {length}s")
print(np.shape(data))

# Plot the waveform.
import matplotlib.pyplot as plt
import numpy as np
time = np.linspace(0., length, data.shape[0])
plt.plot(time, data, label="one channel")
plt.legend()
plt.xlabel("Time [s]")
plt.ylabel("Amplitude")
plt.show()

"""## Pre-processing to Frequency response"""

#Draw FIR data frequency response
from scipy import signal
w, h = signal.freqz(b=data, a=1)
sr=samplerate
x = w * sr * 1.0 / (2 * np.pi)
y = 20 * np.log10(abs(h))
plt.figure(figsize=(10,5))
plt.semilogx(x, y)
plt.ylabel('Amplitude [dB]')
plt.xlabel('Frequency [Hz]')
plt.title('Frequency response')
plt.grid(which='both', linestyle='-', color='grey')
plt.xticks([20, 50, 100, 200, 500, 1000, 2000, 5000, 10000, 20000], ["20", "50", "100", "200", "500", "1K", "2K", "5K", "10K", "20K"])
plt.show()

y = wavIR_reader('/content/Wav_IR_dataset/Marshall1960A_1105/SEVR2/Marshall_SEVR 1.wav')

x = w * sr * 1.0 / (2 * np.pi)
plt.figure(figsize=(10,5))
plt.semilogx(x, y)
plt.ylabel('Amplitude [dB]')
plt.xlabel('Frequency [Hz]')
plt.title('Frequency response')
plt.grid(which='both', linestyle='-', color='grey')
plt.xticks([20, 50, 100, 200, 500, 1000, 2000, 5000, 10000, 20000], ["20", "50", "100", "200", "500", "1K", "2K", "5K", "10K", "20K"])
plt.show()

# Load the .wav file contents.

def wavFR_reader(wav_fname):
  data_=[]
  for wav in wav_fname:
    samplerate, data = wavfile.read(wav)
    idx = np.argmax(data)
    w, h = signal.freqz(b=data[idx:], a=1)
    y = 20 * np.log10(abs(h))
    data_.append(y)
  return data_

def wavIR_reader(wav_fname):
  data_=[]
  for wav in wav_fname:
    samplerate, y = wavfile.read(wav)
    idx = np.argmax(y)
    print(idx)
    data_.append(y[idx:idx+16000])
  return data_

"""## Estiblished audio database"""

import glob
files = glob.glob("/content/Wav_IR_dataset/Marshall1960A_1105/**/*wav")
print(np.shape(files))
x=list(files)
data=wavIR_reader(x)

import tensorflow as tf

train_dataset = tf.data.Dataset.from_tensor_slices(data)
# train_dataset = train_dataset.map(wavIR_reader).padding_batch(2)

for i in train_dataset:
  print(np.shape(i))
  w, h = signal.freqz(b=i, a=1)
  x = w * 96000 * 1.0 / (2 * np.pi)
  y = 20 * np.log10(abs(h))
  plt.figure(figsize=(10,5))
  plt.semilogx(x, y)
  plt.ylabel('Amplitude [dB]')
  plt.xlabel('Frequency [Hz]')
  plt.title('Frequency response')
  plt.grid(which='both', linestyle='-', color='grey')
  plt.xticks([20, 50, 100, 200, 500, 1000, 2000, 5000, 10000, 20000], ["20", "50", "100", "200", "500", "1K", "2K", "5K", "10K", "20K"])
  plt.show()

for i in train_dataset:
  print(np.shape(i))
  length = i.shape[0] / samplerate
  time = np.linspace(0., length, i.shape[0])
  plt.plot(time, i, label="one channel")
  plt.legend()
  plt.xlabel("Time [s]")
  plt.ylabel("Amplitude")
  plt.show()



"""# AI model (1D-VAE)"""

from keras.layers import Input, Dense, Lambda
from keras.models import Model
from keras import backend, optimizers
from keras.losses import MeanSquaredError, binary_crossentropy

latentdim = 10 #Latent space空間為度
Signal_dim=16000
#Encoder network
x = Input(shape=(Signal_dim,))
x = Dense(1000)(x)
x = Dense(200,activation='tanh')(x)
Z_mean = Dense(latentdim)(x)
Z_log_var = Dense(latentdim)(x)

#Decorder network

def latent_space(z_mean,z_var):
  batch= backend.shape(z_mean)[0]
  dim = backend.int_shape(z_mean)[0]
  eps= backend.random_normal(shape=(batch,dim))
  return z_mean+backend.exp(1/2*z_var)*eps

Z = Lambda(latent_space,output_shape=(latentdim,))([Z_mean,Z_log_var])